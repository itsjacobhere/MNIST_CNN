{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('digit-recognizer/train.csv')\n",
    "test = pd.read_csv('digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "x, y = np.array(normalize(train.iloc[:,1:])), np.array(train.iloc[:,0])\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.20)\n",
    "xy_train = np.hstack((x_train,y_train[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator,array_to_img, img_to_array, load_img\n",
    "\n",
    "datagen = ImageDataGenerator( \n",
    "        rotation_range = 30, \n",
    "        shear_range = 0.2, \n",
    "        zoom_range = 0.2, \n",
    "        horizontal_flip = False, \n",
    "        brightness_range = (0.5, 1.5),\n",
    "        width_shift_range=0.1, \n",
    "        height_shift_range=0.1)\n",
    "\n",
    "def augment_images(x, multiplier = 5):\n",
    "    new_imgs = []\n",
    "    i = 0\n",
    "    for batch in datagen.flow(x, batch_size = 1):\n",
    "        i += 1\n",
    "        new_imgs.append(batch)\n",
    "        if i >= multiplier:\n",
    "            break\n",
    "            \n",
    "    return np.vstack(new_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 33600/33600 [01:40<00:00, 335.67it/s]\n"
     ]
    }
   ],
   "source": [
    "# augment images\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "new_data = []\n",
    "new_label = []\n",
    "mult = 10 # create 10 new images for every OG\n",
    "\n",
    "for datum in tqdm(xy_train):\n",
    "    img, label = datum[:-1].reshape(28,28), datum[-1]\n",
    "    \n",
    "    #print(img, label)\n",
    "    \n",
    "    new_x = augment_images(img.reshape(1,28,28,1), multiplier = mult)\n",
    "    new_data.append(new_x)\n",
    "    new_label.append(np.array([label for j in range(mult)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((33600, 784), (10, 28, 28, 1))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape, new_x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge augmented data\n",
    "\n",
    "new_x = np.vstack(new_data)\n",
    "\n",
    "new_y = np.hstack(new_label)\n",
    "\n",
    "x_train = np.vstack([x_train.reshape(-1,28,28,1),new_x])\n",
    "\n",
    "y_train = np.hstack([y_train,new_y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((369600, 28, 28, 1), (369600,))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from tqdm import tqdm\n",
    "\n",
    "import wandb\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn(nn.Module):\n",
    "    \n",
    "    def __init__(self, conv_layers = [16,32], fc_layers = [10,10], padding = 0,\n",
    "                 device = 'cpu'):\n",
    "        super(cnn, self).__init__()\n",
    "        \n",
    "        self.conv_layers = conv_layers\n",
    "        self.fc_layers = fc_layers\n",
    "        \n",
    "        self.device = device\n",
    "        if device is None:\n",
    "            self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "        # hard-coded dropout rate and kernel size\n",
    "        p = 0.2\n",
    "        k = 5\n",
    "        \n",
    "        self.conv_hidden = nn.ModuleList().to(self.device)\n",
    "        self.fc_hidden = nn.ModuleList().to(self.device)\n",
    "        \n",
    "        # conv architecture\n",
    "        self.conv_net_input = nn.Sequential(\n",
    "            nn.Conv2d(1,conv_layers[0],k, stride = 2, padding = padding),\n",
    "            nn.BatchNorm2d(conv_layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        for i in range(len(conv_layers)-2):\n",
    "            self.conv_hidden.append(nn.Conv2d(conv_layers[i],conv_layers[i+1],k, stride = 2, padding = padding))\n",
    "            self.conv_hidden.append(nn.BatchNorm2d(conv_layers[i+1]))\n",
    "            self.conv_hidden.append(nn.ReLU())\n",
    "            self.conv_hidden.append(nn.Dropout(p=p))\n",
    "        self.conv_hidden = nn.Sequential(*self.conv_hidden).to(self.device)\n",
    "        \n",
    "        self.conv_net_output = nn.Sequential(\n",
    "            nn.Conv2d(conv_layers[-2],conv_layers[-1],k, stride = 2, padding = padding),\n",
    "            nn.BatchNorm2d(conv_layers[-1]),\n",
    "            nn.ReLU(),\n",
    "            nn.AdaptiveMaxPool2d((7,7)),\n",
    "            nn.Dropout(p=p)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        # fc architecture\n",
    "        self.fc_input = nn.Sequential(\n",
    "            nn.Linear(conv_layers[-1]*7*7,fc_layers[0]),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(p=p)\n",
    "        ).to(self.device)\n",
    "        \n",
    "        for i in range(len(fc_layers)-1):\n",
    "            self.fc_hidden.append(nn.Linear(fc_layers[i],fc_layers[i+1]))\n",
    "            self.fc_hidden.append(nn.ReLU())\n",
    "            self.fc_hidden.append(nn.Dropout(p=p))\n",
    "        self.fc_hidden = nn.Sequential(*self.fc_hidden).to(self.device)\n",
    "        \n",
    "        self.fc_output = nn.Sequential(\n",
    "            nn.Linear(fc_layers[-1],10),\n",
    "            nn.Softmax(dim = 1)\n",
    "        ).to(self.device)\n",
    "\n",
    "        # apply xavier norm and zero bias initialization\n",
    "        self.conv_net_input.apply(self.init_wandb)\n",
    "        self.conv_hidden.apply(self.init_wandb)\n",
    "        self.conv_net_output.apply(self.init_wandb)\n",
    "        \n",
    "        self.fc_input.apply(self.init_wandb)\n",
    "        self.fc_hidden.apply(self.init_wandb)\n",
    "        self.fc_output.apply(self.init_wandb)\n",
    "        \n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "        self.opt = torch.optim.Adam(self.parameters(), lr = 6e-5)\n",
    "        \n",
    "    def init_wandb(self, l):\n",
    "        # inits weights and biases\n",
    "        if type(l) == nn.Linear or type(l) == nn.Conv2d:\n",
    "            nn.init.xavier_normal_(l.weight.data, gain = 0.1)\n",
    "            nn.init.zeros_(l.bias.data)\n",
    "                \n",
    "    def forward(self, x):\n",
    "        \n",
    "        if not torch.is_tensor(x):\n",
    "            x = torch.from_numpy(x).to(self.device)\n",
    "            \n",
    "        if not x.is_cuda:\n",
    "            x = x.to(self.device)\n",
    "            \n",
    "        #forward prop\n",
    "        x = x.float()\n",
    "        x = self.conv_net_input(x)\n",
    "        x = self.conv_hidden(x)\n",
    "        x = self.conv_net_output(x)\n",
    "        \n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        x = self.fc_input(x)\n",
    "        x = self.fc_hidden(x)\n",
    "        x = self.fc_output(x)\n",
    "        return x\n",
    "    \n",
    "    def train(self, xy_train, x_test, y_test, epochs = 1000, batch_size = 10, name = 'run1'):\n",
    "        \n",
    "        # track training\n",
    "        wandb.init(project = \"digits with CNN\", \n",
    "                   name = name + '_' + str(self.conv_layers) + '_' + str(self.fc_layers))\n",
    "        \n",
    "        \n",
    "        data_loader = torch.utils.data.DataLoader(xy_train, batch_size=batch_size)\n",
    "        y_test = torch.tensor(y_test, dtype=torch.long, device=self.device)\n",
    "        \n",
    "        for i in tqdm(range(int(epochs))):\n",
    "            y_pred = self.forward(x_test.reshape(-1,1,28,28))\n",
    "            \n",
    "            for batch in data_loader: # train in batches\n",
    "                \n",
    "                x_train, y_train = batch[:,:-1].reshape(-1,1,28,28), batch[:,-1]\n",
    "                y_train = torch.tensor(y_train, dtype=torch.long, device=self.device)\n",
    "                \n",
    "                y = self.forward(x_train)\n",
    "                \n",
    "                loss = self.loss_fn(y, y_train) # compute loss\n",
    "                \n",
    "                self.opt.zero_grad() # clear grad buffers\n",
    "                loss.backward() # back prop on loss fn\n",
    "                self.opt.step() # step with optimizer\n",
    "            \n",
    "            # track accuracy through training\n",
    "            train_acc = torch.sum(torch.argmax(y, axis = 1) == y_train) /len(y_train)\n",
    "            test_acc = torch.sum(torch.argmax(y_pred, axis = 1) == y_test ) /len(y_test)\n",
    "            \n",
    "            wandb.log({'train loss': loss.detach().cpu().item(),\n",
    "                   #'test loss': loss_test.detach().cpu().item(),\n",
    "                   'train accuracy': train_acc.detach().cpu().item(),\n",
    "                   'test accuracy': test_acc.detach().cpu().item()\n",
    "                  })\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_train = np.hstack((x_train.reshape(-1,784),y_train[:,None]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(369600, 785)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xy_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner = cnn(conv_layers = [16,64], fc_layers = [784], padding = 1, device = 'cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "cnn(\n",
       "  (conv_hidden): Sequential()\n",
       "  (fc_hidden): Sequential()\n",
       "  (conv_net_input): Sequential(\n",
       "    (0): Conv2d(1, 16, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (conv_net_output): Sequential(\n",
       "    (0): Conv2d(16, 64, kernel_size=(5, 5), stride=(2, 2), padding=(1, 1))\n",
       "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): AdaptiveMaxPool2d(output_size=(7, 7))\n",
       "    (4): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (fc_input): Sequential(\n",
       "    (0): Linear(in_features=3136, out_features=784, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (fc_output): Sequential(\n",
       "    (0): Linear(in_features=784, out_features=10, bias=True)\n",
       "    (1): Softmax(dim=1)\n",
       "  )\n",
       "  (loss_fn): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Currently logged in as: jacob-turner (use `wandb login --relogin` to force relogin)\n",
      "wandb: wandb version 0.12.9 is available!  To upgrade, please run:\n",
      "wandb:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                Tracking run with wandb version 0.10.25<br/>\n",
       "                Syncing run <strong style=\"color:#cdcd00\">CNN__augment_dropout_BN_[16, 64]_[784]</strong> to <a href=\"https://wandb.ai\" target=\"_blank\">Weights & Biases</a> <a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">(Documentation)</a>.<br/>\n",
       "                Project page: <a href=\"https://wandb.ai/jacob-turner/digits%20with%20CNN\" target=\"_blank\">https://wandb.ai/jacob-turner/digits%20with%20CNN</a><br/>\n",
       "                Run page: <a href=\"https://wandb.ai/jacob-turner/digits%20with%20CNN/runs/1rq0vqpl\" target=\"_blank\">https://wandb.ai/jacob-turner/digits%20with%20CNN/runs/1rq0vqpl</a><br/>\n",
       "                Run data is saved locally in <code>C:\\Users\\jdetu\\Google Drive\\Career\\Resume\\2022\\Kaggle\\wandb\\run-20220130_174243-1rq0vqpl</code><br/><br/>\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/100 [00:00<?, ?it/s]<ipython-input-10-d45029a377c0>:117: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  y_train = torch.tensor(y_train, dtype=torch.long, device=self.device)\n",
      "100%|██████████| 100/100 [18:26<00:00, 11.07s/it]\n"
     ]
    }
   ],
   "source": [
    "learner.train(xy_train,x_test,y_test, epochs = 100, batch_size = 1000, name = 'CNN__augment_dropout_BN')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = learner.forward(x_test.reshape(-1,1,28,28)).cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_acc = np.sum(np.argmax(y_pred, axis = 1) == y_test) /len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9983333333333333"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(learner.state_dict(), f'models/CNN_16_64_784_{str(test_acc)[:6]}_final_b4_augmentation_{np.random.rand()}_.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learner.load_state_dict(torch.load('models/CNN_16_64_784_0.9951_final_b4_augmentation_0.9475824963194168_.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_input = normalize(test).reshape(-1,1,28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_pred = learner.forward(test_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28000, 10])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yt_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_pred_final = np.argmax(yt_pred.cpu().detach().numpy(), axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x211f315fca0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 18001\n",
    "plt.title(str(yt_pred_final[i]))\n",
    "\n",
    "plt.imshow(np.array(test.iloc[i,0:]).reshape(28,28))\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "for i in range(1000,2000):\n",
    "    plt.title(f'predicted: {yt_pred_final[i]}', size = 50)\n",
    "    plt.imshow(np.array(test.iloc[i,0:]).reshape(28,28))\n",
    "    plt.show()\n",
    "    clear_output(wait =True)\n",
    "    time.sleep(1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train two nns have them check eachother on the final test set: report conflicting results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yt_pred_final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#augmentation\n",
    "#ensemble\n",
    "#save model at highest test accuracy > 99%\n",
    "#xavier normal initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
